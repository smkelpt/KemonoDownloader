"""
åå°å·¥ä½œçº¿ç¨‹
"""
import os
import time
import concurrent.futures
import threading
from PyQt6.QtCore import QThread, pyqtSignal

from ..utils.i18n import get_text, _
from ..utils.network import (
    COMMON_HEADERS, make_robust_request, parse_json_response,
    get_domain_config, extract_post_info, extract_creator_info
)
from ..utils.formatters import format_name_from_template
from ..core.detector import detect_files_from_post
from ..core.api import get_creator_profile as get_creator_info, get_creator_tags as get_creator_tags_with_counts
from ..core.downloader import download_file, get_file_size


def _get_creator_name(service: str, creator_id: str, domain_config: dict) -> str:
    """è·å–åˆ›ä½œè€…åç§°"""
    creator_info = get_creator_info(service, creator_id, domain_config)
    return creator_info.get('name', creator_id)


# Worker for detecting files from a URL
class DetectionWorker(QThread):
    finished = pyqtSignal(str, str, dict)      # Signal: service, creator_id, domain_config (å¤§æ•°æ®å­˜å‚¨åœ¨å®ä¾‹å±æ€§ä¸­)
    creator_info_detected = pyqtSignal(dict)  # æ–°å¢ï¼šä¼ é€’ä½œè€…ä¿¡æ¯çš„ä¿¡å·
    error = pyqtSignal(str)
    progress_update = pyqtSignal(int, int)  # Signal for progress updates (loaded_count, total_count)

    def __init__(self, url: str, extensions: set, source_filters: set, parent=None):
        super().__init__(parent)
        self.url = url
        self.extensions = extensions
        self.source_filters = source_filters
        
        # å­˜å‚¨æ£€æµ‹ç»“æœï¼ˆé¿å…é€šè¿‡ä¿¡å·ä¼ é€’å¤§æ•°æ®ï¼‰
        self.all_data = []
        self.creator_tags = set()
        self.creator_tags_with_counts = {}

    def run(self):
        try:
            from ..core.detector import get_files_for_url
            all_data = []
            service, creator_id, domain_config = None, None, None
            creator_tags = set()

            # Determine context from URL
            is_creator_url = False
            try: # is it a post url?
                service, creator_id, post_id = extract_post_info(self.url)
            except ValueError: # must be a creator url
                service, creator_id = extract_creator_info(self.url)
                is_creator_url = True
            domain_config = get_domain_config(self.url)

            # å¦‚æœæ˜¯åˆ›ä½œè€…URLï¼Œè·å–å¹¶å‘é€ä½œè€…è¯¦ç»†ä¿¡æ¯
            total_posts = 0
            if is_creator_url:
                creator_info = get_creator_info(service, creator_id, domain_config)
                if creator_info:
                    self.creator_info_detected.emit(creator_info)
                    total_posts = creator_info.get('post_count', 0)

            # Get creator tags for both creator URLs and post URLs
            creator_tags_with_counts = get_creator_tags_with_counts(service, creator_id, domain_config)
            creator_tags = set(creator_tags_with_counts.keys())
            # Store creator tags for later use

            # get_files_for_url yields raw post JSONs for creator URLs,
            # and pre-processed dicts for single post URLs.
            collected_count = 0
            last_update_time = 0
            
            # é¢„å¤„ç†æ‰€æœ‰å¸–å­æ•°æ®ï¼ˆåœ¨workerçº¿ç¨‹ä¸­ï¼‰ï¼Œé¿å…åœ¨ä¸»çº¿ç¨‹UIä¸­å¤„ç†å¤§é‡æ•°æ®å¯¼è‡´æ ˆæº¢å‡º
            creator_name = None
            if is_creator_url:
                creator_name = _get_creator_name(service, creator_id, domain_config)
            
            # ä½¿ç”¨try-exceptåŒ…è£¹è¿­ä»£ï¼Œæ•è·æ½œåœ¨é”™è¯¯
            try:
                for raw_data in get_files_for_url(self.url, self.extensions, self.source_filters):
                    if not raw_data:
                        continue
                    
                    # å¦‚æœæ˜¯å·²å¤„ç†çš„æ•°æ®ï¼ˆæœ‰post_infoå­—æ®µï¼‰ï¼Œç›´æ¥ä½¿ç”¨
                    if 'post_info' in raw_data:
                        all_data.append(raw_data)
                    else:
                        # åŸå§‹æ•°æ®ï¼Œåœ¨workerçº¿ç¨‹ä¸­é¢„å¤„ç†
                        try:
                            post_details, files = detect_files_from_post(
                                raw_data, 
                                domain_config['base_url'].replace('https://', ''), 
                                set(),  # æ£€æµ‹æ‰€æœ‰æ–‡ä»¶ç±»å‹
                                {"file", "attachments", "content"}
                            )
                            
                            # æ˜¾ç¤ºæ‰€æœ‰å¸–å­ï¼Œå³ä½¿æ²¡æœ‰æ–‡ä»¶ï¼ˆä¿æŒä¸ç½‘é¡µé¡ºåºä¸€è‡´ï¼‰
                            post_details['post_title'] = post_details.pop('title', None)
                            post_info = {
                                "service": service.capitalize(), 
                                "creator_id": creator_id, 
                                "creator_name": creator_name,
                                "post_id": post_details.pop('id', None),
                                **post_details
                            }
                            all_data.append({"post_info": post_info, "files": files})  # fileså¯èƒ½ä¸ºç©ºåˆ—è¡¨
                        except Exception as parse_error:
                            # å•ä¸ªå¸–å­è§£æå¤±è´¥ä¸åº”è¯¥ä¸­æ–­æ•´ä¸ªæµç¨‹
                            print(f"âš ï¸ è§£æå¸–å­å¤±è´¥: {parse_error}")
                            continue
                    
                    collected_count += 1
                    
                    # æ¯50ä¸ªå¸–å­æˆ–æ¯0.5ç§’æ›´æ–°ä¸€æ¬¡è¿›åº¦ï¼ˆé¿å…è¿‡äºé¢‘ç¹ï¼‰
                    current_time = time.time()
                    if collected_count % 50 == 0 or (current_time - last_update_time) >= 0.5:
                        self.progress_update.emit(collected_count, total_posts)
                        last_update_time = current_time
            except Exception as iteration_error:
                print(f"âŒ è¿­ä»£è·å–æ–‡ä»¶æ—¶å‘ç”Ÿé”™è¯¯: {iteration_error}")
                import traceback
                traceback.print_exc()
            
            # æ£€æµ‹å®Œæˆåä¿å­˜ç¼“å­˜
            from ..utils.cache import get_cache_manager
            cache = get_cache_manager()
            cache.flush_pending_cache()
            
            # å­˜å‚¨æ•°æ®åˆ°å®ä¾‹å±æ€§ï¼ˆé¿å…é€šè¿‡ä¿¡å·ä¼ é€’å¤§æ•°æ®å¯¼è‡´æ ˆæº¢å‡ºï¼‰
            self.all_data = all_data
            self.creator_tags = creator_tags
            self.creator_tags_with_counts = creator_tags_with_counts
            
            # åªä¼ é€’å…ƒæ•°æ®
            self.finished.emit(service, creator_id, domain_config)
            
        except Exception as e:
            self.error.emit(f"æ£€æµ‹æ–‡ä»¶æ—¶å‘ç”Ÿæœªé¢„æœŸé”™è¯¯: {e}")


# Worker for filtering posts by tags and coordinating downloads
class TagFilterDownloadCoordinator(QThread):
    finished = pyqtSignal()
    error = pyqtSignal(str)
    file_completed = pyqtSignal(str)  # url of the completed file
    progress_update = pyqtSignal(str)  # progress message
    stats_update = pyqtSignal(int, int)  # downloaded_files_count, processed_posts_count
    download_summary = pyqtSignal(dict)  # ä¸‹è½½å®Œæˆåçš„ç»Ÿè®¡ä¿¡æ¯ {success, failed, failed_files}
    file_progress = pyqtSignal(int, int, int)  # downloaded_bytes, total_bytes, retry_count

    def __init__(self, detected_files_data: list, tag_filter_enabled: bool, selected_tags: set, 
                 allowed_exts: set, download_settings: dict, 
                 pause_event, tags_with_counts: dict = None, start_post_id: str = "", end_post_id: str = "", parent=None):
        super().__init__(parent)
        self.detected_files_data = detected_files_data
        self.tag_filter_enabled = tag_filter_enabled
        self.selected_tags = selected_tags
        self.allowed_exts = allowed_exts
        self.download_settings = download_settings
        self.pause_event = pause_event
        self.tags_with_counts = tags_with_counts or {}
        self.start_post_id = start_post_id
        self.end_post_id = end_post_id
        
        # UIæ‰¹é‡æ›´æ–°ä¼˜åŒ–
        self.ui_update_batch_size = 5  # æ¯5ä¸ªæ–‡ä»¶æ›´æ–°ä¸€æ¬¡UI
        self.ui_update_interval = 1000  # 1ç§’å¼ºåˆ¶æ›´æ–°ä¸€æ¬¡
        self.last_ui_update = 0
        self.last_downloaded_count = 0
        self.last_processed_count = 0
        
        # å¤§æ–‡ä»¶ä¸‹è½½æ§åˆ¶ï¼ˆ50MBé˜ˆå€¼ï¼‰
        self.large_file_threshold = 50 * 1024 * 1024  # 50MB in bytes
        self.large_file_future = None  # å½“å‰æ­£åœ¨ä¸‹è½½çš„å¤§æ–‡ä»¶çš„futureå¯¹è±¡
        self.current_large_file_lock = threading.Lock()
        self.current_large_file_progress = None  # (downloaded, total)
        self.retry_count = 0  # æ­£åœ¨é‡è¯•çš„æ–‡ä»¶æ•°
        
        # è·Ÿè¸ªæ‰€æœ‰æ–‡ä»¶çš„ä¸‹è½½è¿›åº¦
        self.all_files_progress = {}  # {url: (downloaded, total)}
        self.all_files_progress_lock = threading.Lock()
        
        # è·Ÿè¸ªæ­£åœ¨é‡è¯•çš„æ–‡ä»¶
        self.retrying_files = set()  # æ­£åœ¨é‡è¯•çš„æ–‡ä»¶URLé›†åˆ
        self.retrying_files_lock = threading.Lock()
    
    def is_ext_match(self, file_ext: str) -> bool:
        """
        åˆ¤æ–­æ–‡ä»¶æ‰©å±•åæ˜¯å¦åŒ¹é…è¿‡æ»¤å™¨
        å¦‚æœallowed_extsåŒ…å«.001ï¼Œåˆ™.001-.999éƒ½ä¼šè¢«åŒ¹é…
        """
        # ç›´æ¥åŒ¹é…
        if file_ext in self.allowed_exts:
            return True
        
        # å¦‚æœ.001åœ¨è¿‡æ»¤å™¨ä¸­ï¼Œæ£€æŸ¥æ˜¯å¦ä¸ºæ•°å­—æ‰©å±•åï¼ˆ.001-.999ï¼‰
        if ".001" in self.allowed_exts and file_ext.startswith(".") and len(file_ext) == 4:
            # æ£€æŸ¥æ˜¯å¦ä¸º3ä½æ•°å­—
            if file_ext[1:].isdigit():
                return True
        
        return False

    def _should_update_ui(self, downloaded_files_count, matched_posts_count):
        """åˆ¤æ–­æ˜¯å¦åº”è¯¥æ›´æ–°UI"""
        current_time = time.time() * 1000  # è½¬æ¢ä¸ºæ¯«ç§’
        
        # æ£€æŸ¥æ˜¯å¦è¾¾åˆ°æ‰¹é‡å¤§å°
        files_diff = downloaded_files_count - self.last_downloaded_count
        
        # è¾¾åˆ°æ‰¹é‡å¤§å°æˆ–è¶…è¿‡æ—¶é—´é—´éš”æ—¶æ›´æ–°
        if (files_diff >= self.ui_update_batch_size or 
            current_time - self.last_ui_update >= self.ui_update_interval):
            self.last_ui_update = current_time
            self.last_downloaded_count = downloaded_files_count
            self.last_processed_count = matched_posts_count
            return True
        return False
    
    def _create_progress_callback(self, url: str, is_large_file: bool):
        """åˆ›å»ºè¿›åº¦å›è°ƒå‡½æ•°"""
        last_emit_time = [0]  # ä½¿ç”¨åˆ—è¡¨æ¥å­˜å‚¨å¯å˜å€¼
        min_emit_interval = 0.1  # æœ€å°å‘å°„é—´éš”ï¼ˆç§’ï¼‰
        
        def callback(downloaded, total):
            # è®°å½•æ‰€æœ‰æ–‡ä»¶çš„è¿›åº¦
            with self.all_files_progress_lock:
                self.all_files_progress[url] = (downloaded, total)
            
            # é™åˆ¶ä¿¡å·å‘å°„é¢‘ç‡ï¼Œé¿å…æ ˆæº¢å‡º
            current_time = time.time()
            if current_time - last_emit_time[0] < min_emit_interval:
                return  # è·³è¿‡å¤ªé¢‘ç¹çš„æ›´æ–°
            
            last_emit_time[0] = current_time
            
            # å¦‚æœæ˜¯å¤§æ–‡ä»¶ï¼Œå•ç‹¬è®°å½•å¹¶å‘é€ä¿¡å·
            if is_large_file:
                with self.current_large_file_lock:
                    self.current_large_file_progress = (downloaded, total)
                # å‘é€å¤§æ–‡ä»¶è¿›åº¦ä¿¡å·
                self.file_progress.emit(downloaded, total, self.retry_count)
            else:
                # å°æ–‡ä»¶ï¼šå¦‚æœæ²¡æœ‰å¤§æ–‡ä»¶åœ¨ä¸‹è½½ï¼Œå‘é€æ‰€æœ‰æ–‡ä»¶çš„ç»¼åˆè¿›åº¦
                with self.current_large_file_lock:
                    has_large_file = self.current_large_file_progress is not None
                
                if not has_large_file:
                    # è®¡ç®—æ‰€æœ‰å°æ–‡ä»¶çš„æ€»è¿›åº¦
                    with self.all_files_progress_lock:
                        total_downloaded = sum(d for d, t in self.all_files_progress.values())
                        total_size = sum(t for d, t in self.all_files_progress.values())
                    
                    if total_size > 0:
                        self.file_progress.emit(total_downloaded, total_size, self.retry_count)
        return callback
    
    def _create_retry_callback(self, url: str):
        """åˆ›å»ºé‡è¯•å›è°ƒå‡½æ•°"""
        def callback(attempt, is_retrying):
            with self.retrying_files_lock:
                if is_retrying:
                    # æ–‡ä»¶æ­£åœ¨é‡è¯•ï¼ŒåŠ å…¥é›†åˆ
                    self.retrying_files.add(url)
                else:
                    # æ–‡ä»¶ä¸‹è½½æˆåŠŸæˆ–åœæ­¢é‡è¯•ï¼Œä»é›†åˆç§»é™¤
                    self.retrying_files.discard(url)
                
                # æ›´æ–°é‡è¯•è®¡æ•°
                self.retry_count = len(self.retrying_files)
        return callback

    def run(self):
        try:
            # æ—©æœŸæ£€æŸ¥ï¼šå¦‚æœæ²¡æœ‰å…è®¸çš„æ‰©å±•åï¼Œç›´æ¥ç»“æŸ
            if not self.allowed_exts:
                return
            
            # æ—©æœŸæ£€æŸ¥ï¼šé¢„å…ˆæ‰«ææ˜¯å¦æœ‰ä»»ä½•ç¬¦åˆæ‰©å±•åæ¡ä»¶çš„æ–‡ä»¶
            has_eligible_files = False
            for post_data in self.detected_files_data:
                files_in_post = post_data.get("files", [])
                for file_info in files_in_post:
                    file_ext = os.path.splitext(file_info.get("name", ""))[1].lower()
                    if self.is_ext_match(file_ext):
                        has_eligible_files = True
                        break
                if has_eligible_files:
                    break
            
            # å¦‚æœæ²¡æœ‰ç¬¦åˆæ‰©å±•åæ¡ä»¶çš„æ–‡ä»¶ï¼Œç›´æ¥ç»“æŸ
            if not has_eligible_files:
                return
            
            # Create download executor with optimized settings
            max_workers = min(self.download_settings['threads'], 10)  # é™åˆ¶æœ€å¤§çº¿ç¨‹æ•°
            executor = concurrent.futures.ThreadPoolExecutor(
                max_workers=max_workers,
                thread_name_prefix="download"
            )
            download_futures = {}
            active_downloads = 0  # è·Ÿè¸ªæ´»è·ƒä¸‹è½½æ•°
            
            total_posts = len(self.detected_files_data)
            processed_posts = 0
            matched_posts_count = 0  # ç”¨äºæ—©æœŸç»ˆæ­¢çš„è®¡æ•°å™¨
            downloaded_files_count = 0  # å·²ä¸‹è½½æ–‡ä»¶è®¡æ•°
            failed_files_count = 0  # å¤±è´¥æ–‡ä»¶è®¡æ•°
            failed_files_list = []  # å¤±è´¥æ–‡ä»¶åˆ—è¡¨ [(file_name, url, error)]
            
            # è·Ÿè¸ªæ¯ä¸ªå¸–å­çš„ä¸‹è½½æƒ…å†µï¼ˆç®€å•è®¡æ•°ï¼‰
            post_download_tracker = {}  # {post_key: {"total": 10, "completed": 5, "post_info": {...}}}
            url_to_post_key = {}  # URL -> post_key æ˜ å°„ï¼Œç”¨äºåœ¨ä¸‹è½½å®Œæˆæ—¶æ‰¾åˆ°å¯¹åº”çš„å¸–å­
            
            # å¸–å­IDèŒƒå›´è¿‡æ»¤
            started = not self.start_post_id  # å¦‚æœæ²¡æœ‰èµ·å§‹IDï¼Œåˆ™ä»ä¸€å¼€å§‹å°±å¯ç”¨
            
            for post_data in self.detected_files_data:
                if self.pause_event.is_set():
                    # Gracefully shutdown executor
                    executor.shutdown(wait=False, cancel_futures=True)
                    return
                    
                try:
                    post_info = post_data.get("post_info", {})
                    post_id = str(post_info.get('post_id', ''))
                    
                    # æ£€æŸ¥æ˜¯å¦åˆ°è¾¾èµ·å§‹å¸–å­ID
                    if not started:
                        if post_id == self.start_post_id:
                            started = True
                            # æ‰¾åˆ°èµ·å§‹IDï¼Œç»§ç»­å¤„ç†è¿™ä¸ªå¸–å­ï¼ˆä¸è·³è¿‡ï¼‰
                        else:
                            continue  # è·³è¿‡èµ·å§‹IDä¹‹å‰çš„å¸–å­
                    
                    processed_posts += 1
                    files_in_post = post_data.get("files", [])
                    
                    # è¿›åº¦è¾“å‡ºï¼ˆç®€åŒ–ï¼šåªåœ¨å…³é”®èŠ‚ç‚¹æ˜¾ç¤ºï¼‰
                    if processed_posts == 1 or processed_posts % 50 == 0:
                        if self.tag_filter_enabled and self.selected_tags:
                            # æ ‡ç­¾è¿‡æ»¤ï¼šåªæ˜¾ç¤ºå·²å¤„ç†æ•°é‡ï¼Œä¸æ˜¾ç¤ºæ€»æ•°
                            tags_preview = "ã€".join(list(self.selected_tags)[:3])
                            if len(self.selected_tags) > 3:
                                tags_preview += "..."
                            print(f"ğŸ“Š å¤„ç†: {processed_posts} å¸–å­ (æ ‡ç­¾: {tags_preview})")
                        else:
                            # æœªå¯ç”¨æ ‡ç­¾è¿‡æ»¤ï¼šæ˜¾ç¤ºæ‰€æœ‰å¸–å­æ€»æ•°
                            print(f"ğŸ“Š å¤„ç†: {processed_posts}/{total_posts} å¸–å­")
                    
                    # === æ ‡ç­¾è¿‡æ»¤æ£€æŸ¥ ===
                    # If tag filtering is enabled, we need to get detailed post data to check tags
                    if self.tag_filter_enabled and self.selected_tags:
                        # Get detailed post data via post API
                        post_id = post_info.get('post_id')
                        creator_id = post_info.get('creator_id')
                        service = post_info.get('service', '').lower()
                        
                        if not all([post_id, creator_id, service]):
                            continue  # è·³è¿‡å¸–å­ï¼šç¼ºå°‘å¿…è¦ä¿¡æ¯
                        
                        # Construct post API URL
                        # We need domain config, let's determine it from service
                        if service == 'patreon':
                            domain_config = {'api_base': 'https://kemono.cr/api/v1', 'referer': 'https://kemono.cr/', 'base_url': 'https://kemono.cr'}
                        else:
                            domain_config = {'api_base': 'https://coomer.st/api/v1', 'referer': 'https://coomer.st/', 'base_url': 'https://coomer.st'}
                        
                        post_api_url = f"{domain_config['api_base']}/{service}/user/{creator_id}/post/{post_id}"
                        
                        # Get detailed post data
                        headers = COMMON_HEADERS.copy()
                        headers["Referer"] = domain_config['referer']
                        
                        try:
                            response = make_robust_request(post_api_url, headers, max_retries=2, timeout=15)
                            if not response:
                                continue  # è·³è¿‡å¸–å­ï¼ˆAPIè¯·æ±‚å¤±è´¥ï¼‰
                            
                            detailed_post_data = parse_json_response(response)
                            if not detailed_post_data:
                                continue  # è·³è¿‡å¸–å­ï¼ˆæ•°æ®è§£æå¤±è´¥ï¼‰
                        except Exception as api_error:
                            continue  # è·³è¿‡å¸–å­ï¼ˆè¯·æ±‚å¼‚å¸¸ï¼‰
                        
                        # Extract tags from detailed post data
                        actual_post_content = detailed_post_data.get('post', detailed_post_data)
                        post_tags = set(actual_post_content.get('tags', []) or [])
                        
                        # Apply tag filtering (åŒ…å«æ¨¡å¼ï¼šå¸–å­å¿…é¡»åŒ…å«æ‰€æœ‰é€‰ä¸­çš„æ ‡ç­¾)
                        post_matches_filter = self.selected_tags.issubset(post_tags)
                        
                        # Skip post if it doesn't match filter
                        if not post_matches_filter:
                            continue
                        
                        # Re-detect files from detailed post data to ensure we have complete file info
                        post_details, updated_files = detect_files_from_post(
                            detailed_post_data,
                            domain_config['base_url'].replace('https://', ''),
                            self.allowed_exts,
                            {"file", "attachments", "content"}
                        )
                        files_in_post = updated_files
                
                    # Count eligible files in this post
                    eligible_files_count = 0
                    for file_info in files_in_post:
                        file_ext = os.path.splitext(file_info.get("name", ""))[1].lower()
                        if self.is_ext_match(file_ext):
                            eligible_files_count += 1
                    
                    # Only log and process if post has eligible files
                    if eligible_files_count > 0:
                        matched_posts_count += 1
                        post_title = post_info.get('post_title', 'Untitled')
                    else:
                        # Skip if no eligible files
                        continue
                
                    # åˆå§‹åŒ–å¸–å­ä¸‹è½½è·Ÿè¸ª
                    service = post_info.get('service', '').lower()
                    creator_id_str = str(post_info.get('creator_id', ''))
                    post_id_str = str(post_info.get('post_id', ''))
                    post_key = f"{service}:{creator_id_str}:{post_id_str}"
                    
                    if post_key and post_key not in post_download_tracker:
                        post_download_tracker[post_key] = {
                            "total": eligible_files_count,
                            "completed": 0,
                            "post_info": post_info
                        }
                    
                    # Process files in this post
                    for file_info in files_in_post:
                        # åœ¨å¤„ç†æ¯ä¸ªæ–‡ä»¶å‰æ£€æŸ¥æš‚åœä¿¡å·
                        if self.pause_event.is_set():
                            print(f"â¸ï¸ æ£€æµ‹åˆ°æš‚åœä¿¡å·ï¼Œåœæ­¢æäº¤æ–°ä»»åŠ¡...")
                            executor.shutdown(wait=False, cancel_futures=True)
                            return
                        
                        file_name_with_ext = file_info.get("name", "")
                        
                        # ç¡®ä¿æ–‡ä»¶ååŒ…å«æ‰©å±•å
                        if not file_name_with_ext:
                            continue
                        
                        file_name_original, file_ext_with_dot = os.path.splitext(file_name_with_ext)
                        
                        # å¦‚æœåˆ†ç¦»åæ²¡æœ‰æ‰©å±•åï¼Œå°è¯•ä»URLä¸­è·å–
                        if not file_ext_with_dot:
                            url = file_info.get("url", "")
                            _, url_ext = os.path.splitext(url.split('?')[0])  # ç§»é™¤URLå‚æ•°
                            if url_ext:
                                file_ext_with_dot = url_ext.lower()
                                file_name_with_ext = file_name_original + file_ext_with_dot
                        
                        # Check if file extension is allowed
                        if not self.is_ext_match(file_ext_with_dot.lower()):
                            continue
                        
                        # æœ€åç¡®ä¿æ‰©å±•åå­˜åœ¨ï¼ˆå®‰å…¨æ£€æŸ¥ï¼‰
                        if not file_ext_with_dot:
                            continue
                        
                        # Construct file path
                        creator_folder_name = format_name_from_template(
                            self.download_settings["creator_folder_name_template"], post_info
                        )
                        post_folder_name = format_name_from_template(
                            self.download_settings["post_folder_name_template"], post_info
                        )
                        
                        file_name_data = {
                            **post_info, 
                            "file_name_original": file_name_original, 
                            "file_ext": file_ext_with_dot 
                        }
                        
                        final_file_name = format_name_from_template(
                            self.download_settings["file_name_template"], file_name_data
                        )
                        
                        full_path = os.path.join(
                            self.download_settings["download_root"], 
                            creator_folder_name, 
                            post_folder_name, 
                            final_file_name
                        )
                        
                        # åŠæ—¶æ¸…ç†å·²å®Œæˆçš„ä»»åŠ¡ï¼Œé¿å…é˜Ÿåˆ—å †ç§¯
                        completed_futures = []
                        for future in list(download_futures.keys()):
                            if future.done():
                                completed_futures.append(future)
                        
                        # å¤„ç†æ‰€æœ‰å·²å®Œæˆçš„ä»»åŠ¡ï¼ˆé™é»˜æ¸…ç†ï¼‰
                        if len(completed_futures) > 0:
                            pass  # é™é»˜æ¸…ç†å·²å®Œæˆçš„ä»»åŠ¡
                        
                        for completed_future in completed_futures:
                            url = download_futures[completed_future]
                            del download_futures[completed_future]
                            
                            # æ¸…ç†è¯¥æ–‡ä»¶çš„è¿›åº¦è®°å½•
                            with self.all_files_progress_lock:
                                self.all_files_progress.pop(url, None)
                            
                            # å¦‚æœæ˜¯å¤§æ–‡ä»¶ï¼Œæ¸…ç†å¤§æ–‡ä»¶è¿›åº¦
                            if completed_future == self.large_file_future:
                                with self.current_large_file_lock:
                                    self.current_large_file_progress = None
                                self.large_file_future = None
                            
                            try:
                                path, file_hash = completed_future.result()
                                if path:
                                    downloaded_files_count += 1
                                    if self._should_update_ui(downloaded_files_count, matched_posts_count):
                                        self.stats_update.emit(downloaded_files_count, matched_posts_count)
                                    
                                    # æ›´æ–°å¸–å­ä¸‹è½½è®¡æ•°
                                    p_key = url_to_post_key.get(url)
                                    if p_key and p_key in post_download_tracker:
                                        post_download_tracker[p_key]["completed"] += 1
                                        tracker = post_download_tracker[p_key]
                                        
                                        # å¦‚æœå¸–å­æ‰€æœ‰æ–‡ä»¶éƒ½ä¸‹è½½å®Œæˆï¼Œæ˜¾ç¤ºæç¤º
                                        if tracker["completed"] >= tracker["total"]:
                                            p_info = tracker["post_info"]
                                            print(f"âœ… å¸–å­å·²å®Œæˆ: {p_info.get('post_title', 'Untitled')} ({tracker['completed']}/{tracker['total']})")
                                else:
                                    failed_files_count += 1
                            except Exception as e:
                                failed_files_count += 1
                                file_name = os.path.basename(url)
                                failed_files_list.append((file_name, url, str(e)))
                        
                        # å¦‚æœé˜Ÿåˆ—å¤ªæ»¡ï¼Œç­‰å¾…ä»»åŠ¡å®Œæˆï¼ˆé¿å…å†…å­˜å ç”¨è¿‡é«˜ï¼‰
                        wait_attempts = 0
                        max_wait_attempts = 10  # æœ€å¤šç­‰å¾…10æ¬¡
                        while len(download_futures) >= max_workers * 3:
                            if wait_attempts >= max_wait_attempts:
                                # é˜Ÿåˆ—è¿‡æ»¡ä½†ç­‰å¾…è¶…æ—¶ï¼Œå¼ºåˆ¶ç»§ç»­æ·»åŠ ä»»åŠ¡
                                break
                            
                            try:
                                # æ£€æŸ¥æ˜¯å¦æœ‰ä»»åŠ¡å®Œæˆ
                                if not download_futures:
                                    break
                                
                                completed_future = next(concurrent.futures.as_completed(download_futures.keys(), timeout=0.5))
                                url = download_futures[completed_future]
                                del download_futures[completed_future]
                                
                                # æ¸…ç†è¯¥æ–‡ä»¶çš„è¿›åº¦è®°å½•
                                with self.all_files_progress_lock:
                                    self.all_files_progress.pop(url, None)
                                
                                # å¦‚æœæ˜¯å¤§æ–‡ä»¶ï¼Œæ¸…ç†å¤§æ–‡ä»¶è¿›åº¦
                                if completed_future == self.large_file_future:
                                    with self.current_large_file_lock:
                                        self.current_large_file_progress = None
                                    self.large_file_future = None
                                
                                try:
                                    path, file_hash = completed_future.result()
                                    if path:
                                        downloaded_files_count += 1
                                        if self._should_update_ui(downloaded_files_count, matched_posts_count):
                                            self.stats_update.emit(downloaded_files_count, matched_posts_count)
                                    else:
                                        failed_files_count += 1
                                except Exception as e:
                                    failed_files_count += 1
                                    file_name = os.path.basename(url)
                                    failed_files_list.append((file_name, url, str(e)))
                                
                                break
                            except concurrent.futures.TimeoutError:
                                wait_attempts += 1
                                # è¶…æ—¶åå†æ¬¡æ£€æŸ¥å·²å®Œæˆçš„ä»»åŠ¡
                                for future in list(download_futures.keys()):
                                    if future.done():
                                        url = download_futures[future]
                                        del download_futures[future]
                                        
                                        # æ¸…ç†è¯¥æ–‡ä»¶çš„è¿›åº¦è®°å½•
                                        with self.all_files_progress_lock:
                                            self.all_files_progress.pop(url, None)
                                        
                                        # å¦‚æœæ˜¯å¤§æ–‡ä»¶ï¼Œæ¸…ç†å¤§æ–‡ä»¶è¿›åº¦
                                        if future == self.large_file_future:
                                            with self.current_large_file_lock:
                                                self.current_large_file_progress = None
                                            self.large_file_future = None
                                        
                                        try:
                                            path, file_hash = future.result()
                                            if path:
                                                downloaded_files_count += 1
                                        except:
                                            pass
                                continue
                        
                        # æ£€æŸ¥æ–‡ä»¶å¤§å°ä»¥å†³å®šä¸‹è½½ç­–ç•¥
                        file_url = file_info["url"]
                        file_size = get_file_size(file_url, COMMON_HEADERS, timeout=5)
                        is_large_file = file_size > self.large_file_threshold
                        
                        # å¦‚æœæ˜¯å¤§æ–‡ä»¶ï¼ˆ>50MBï¼‰ï¼Œç­‰å¾…ä¹‹å‰çš„å¤§æ–‡ä»¶ä¸‹è½½å®Œæˆ
                        if is_large_file:
                            if self.large_file_future and not self.large_file_future.done():
                                # ç­‰å¾…å½“å‰å¤§æ–‡ä»¶ä¸‹è½½å®Œæˆ
                                prev_url = download_futures.get(self.large_file_future)
                                try:
                                    path, file_hash = self.large_file_future.result()
                                    if path:
                                        downloaded_files_count += 1
                                        if self._should_update_ui(downloaded_files_count, matched_posts_count):
                                            self.stats_update.emit(downloaded_files_count, matched_posts_count)
                                        
                                        # æ›´æ–°å¸–å­ä¸‹è½½è®¡æ•°
                                        if prev_url:
                                            p_key = url_to_post_key.get(prev_url)
                                            if p_key and p_key in post_download_tracker:
                                                post_download_tracker[p_key]["completed"] += 1
                                                tracker = post_download_tracker[p_key]
                                                if tracker["completed"] >= tracker["total"]:
                                                    p_info = tracker["post_info"]
                                                    print(f"âœ… å¸–å­å·²å®Œæˆ: {p_info.get('post_title', 'Untitled')} ({tracker['completed']}/{tracker['total']})")
                                    else:
                                        failed_files_count += 1
                                except Exception as e:
                                    failed_files_count += 1
                                    if prev_url:
                                        file_name = os.path.basename(prev_url)
                                        failed_files_list.append((file_name, prev_url, str(e)))
                                
                                # æ¸…ç†å·²å®Œæˆçš„futureå’Œè¿›åº¦è®°å½•
                                if self.large_file_future in download_futures:
                                    del download_futures[self.large_file_future]
                                if prev_url:
                                    with self.all_files_progress_lock:
                                        self.all_files_progress.pop(prev_url, None)
                                # æ¸…ç†å¤§æ–‡ä»¶è¿›åº¦æ ‡è®°
                                with self.current_large_file_lock:
                                    self.current_large_file_progress = None
                                self.large_file_future = None
                            
                            # æäº¤æ–°çš„å¤§æ–‡ä»¶ä¸‹è½½ä»»åŠ¡
                            file_size_mb = file_size / (1024 * 1024)
                            print(f"ğŸ“¦ å¤§æ–‡ä»¶æ£€æµ‹: {final_file_name} ({file_size_mb:.1f}MB) - ä½¿ç”¨ä¸²è¡Œä¸‹è½½")
                        
                        # Submit download taskï¼ˆä¸ºæ‰€æœ‰æ–‡ä»¶åˆ›å»ºè¿›åº¦å›è°ƒå’Œé‡è¯•å›è°ƒï¼‰
                        progress_callback = self._create_progress_callback(file_url, is_large_file)
                        retry_callback = self._create_retry_callback(file_url)
                        future = executor.submit(
                            download_file, 
                            file_url, 
                            full_path, 
                            COMMON_HEADERS, 
                            cancel_event=self.pause_event,
                            progress_callback=progress_callback,
                            retry_callback=retry_callback
                        )
                        download_futures[future] = file_url  # æ¢å¤åŸå§‹ç»“æ„
                        url_to_post_key[file_url] = post_key  # å»ºç«‹URLåˆ°å¸–å­çš„æ˜ å°„
                        active_downloads += 1
                        
                        # å¦‚æœæ˜¯å¤§æ–‡ä»¶ï¼Œè®°å½•å…¶futureä»¥ä¾¿åç»­ç­‰å¾…
                        if is_large_file:
                            self.large_file_future = future
                    
                    # æ£€æŸ¥æ˜¯å¦åˆ°è¾¾ç»“æŸå¸–å­ID
                    if self.end_post_id and post_id == self.end_post_id:
                        print(f"âœ… å·²åˆ°è¾¾ç»“æŸå¸–å­ID: {self.end_post_id}ï¼Œåœæ­¢ä¸‹è½½")
                        break
                        
                except Exception as post_error:
                    # å•ä¸ªå¸–å­å¤„ç†å¤±è´¥ä¸åº”è¯¥ä¸­æ–­æ•´ä¸ªä¸‹è½½è¿›ç¨‹
                    post_title = post_info.get('post_title', 'Unknown') if 'post_info' in locals() else 'Unknown'
                    print(f"âš ï¸ å¤„ç†å¸–å­ '{post_title}' æ—¶å‡ºé”™: {post_error}")
                    import traceback
                    traceback.print_exc()
                    continue
            
            print(f"âœ“ å¸–å­æ£€æµ‹å®Œæˆï¼Œå…±å¤„ç† {processed_posts}/{total_posts} ä¸ªå¸–å­ï¼ŒåŒ¹é… {matched_posts_count} ä¸ª")
            
            # Wait for all downloads to complete
            completed_count = 0
            total_downloads = len(download_futures)
            
            print(f"ğŸ“¥ ç­‰å¾…ä»»åŠ¡å®Œæˆ...")
            
            # å¦‚æœæ²¡æœ‰ä¸‹è½½ä»»åŠ¡ï¼Œç›´æ¥ç»“æŸ
            if total_downloads == 0:
                print("âœ“ æ²¡æœ‰ç¬¦åˆæ¡ä»¶çš„æ–‡ä»¶éœ€è¦ä¸‹è½½")
                return
            
            try:
                # å…ˆæ¸…ç†æ‰€æœ‰å·²å®Œæˆçš„ä»»åŠ¡
                # æ£€æŸ¥å·²å®Œæˆçš„ä»»åŠ¡
                completed_futures = []
                for future in list(download_futures.keys()):
                    if future.done():
                        completed_futures.append(future)
                
                # å¤„ç†å·²å®Œæˆçš„ä»»åŠ¡
                for completed_future in completed_futures:
                    url = download_futures[completed_future]
                    del download_futures[completed_future]
                    completed_count += 1
                    
                    # æ¸…ç†è¯¥æ–‡ä»¶çš„è¿›åº¦è®°å½•
                    with self.all_files_progress_lock:
                        self.all_files_progress.pop(url, None)
                    
                    # æ¸…ç†è¯¥æ–‡ä»¶çš„é‡è¯•çŠ¶æ€
                    with self.retrying_files_lock:
                        self.retrying_files.discard(url)
                        self.retry_count = len(self.retrying_files)
                    
                    # å¦‚æœæ˜¯å¤§æ–‡ä»¶ï¼Œæ¸…ç†å¤§æ–‡ä»¶è¿›åº¦
                    if completed_future == self.large_file_future:
                        with self.current_large_file_lock:
                            self.current_large_file_progress = None
                        self.large_file_future = None
                    
                    try:
                        path, file_hash = completed_future.result()
                        if path:
                            downloaded_files_count += 1
                        else:
                            failed_files_count += 1
                    except Exception as e:
                        failed_files_count += 1
                        file_name = os.path.basename(url)
                        failed_files_list.append((file_name, url, str(e)))
                
                # æ›´æ–°å‰©ä½™ä»»åŠ¡æ•°
                remaining_tasks = len(download_futures)
                # ç­‰å¾…å‰©ä½™ä»»åŠ¡
                
                # ç­‰å¾…å‰©ä½™çš„ä»»åŠ¡
                if remaining_tasks > 0:
                    pass  # ç­‰å¾…å‰©ä½™ä»»åŠ¡
                    processed_in_loop = 0
                    for future in concurrent.futures.as_completed(download_futures, timeout=None):
                        if self.pause_event.is_set():
                            print("â¸ï¸  æ£€æµ‹åˆ°æš‚åœä¿¡å·")
                            break  # æ£€æµ‹åˆ°æš‚åœä¿¡å·
                            
                        url = download_futures[future]
                        completed_count += 1
                        processed_in_loop += 1
                        
                        # æ¸…ç†è¯¥æ–‡ä»¶çš„è¿›åº¦è®°å½•
                        with self.all_files_progress_lock:
                            self.all_files_progress.pop(url, None)
                        
                        # æ¸…ç†è¯¥æ–‡ä»¶çš„é‡è¯•çŠ¶æ€
                        with self.retrying_files_lock:
                            self.retrying_files.discard(url)
                            self.retry_count = len(self.retrying_files)
                        
                        # å¦‚æœæ˜¯å¤§æ–‡ä»¶ï¼Œæ¸…ç†å¤§æ–‡ä»¶è¿›åº¦
                        if future == self.large_file_future:
                            with self.current_large_file_lock:
                                self.current_large_file_progress = None
                            self.large_file_future = None
                        
                        # æ˜¾ç¤ºè¿›åº¦ï¼ˆç®€åŒ–ï¼‰
                        if completed_count % 50 == 0 or completed_count == total_downloads:
                            print(f"â³ {completed_count}/{total_downloads}")
                        
                        try:
                            path, file_hash = future.result()
                            if path:  # åªè¦æœ‰è·¯å¾„å°±è®¤ä¸ºä¸‹è½½æˆåŠŸ
                                downloaded_files_count += 1
                                # åªåœ¨æ»¡è¶³æ¡ä»¶æ—¶æ›´æ–°UIï¼Œå‡å°‘ä¿¡å·å‘é€é¢‘ç‡
                                if self._should_update_ui(downloaded_files_count, matched_posts_count):
                                    self.stats_update.emit(downloaded_files_count, matched_posts_count)
                            else:
                                failed_files_count += 1
                                file_name = os.path.basename(url)
                                failed_files_list.append((file_name, url, "Download returned None"))
                        except InterruptedError:
                            print("â¸ï¸  ä»»åŠ¡è¢«ä¸­æ–­")
                            continue  # ä¸‹è½½å·²æš‚åœï¼ˆä¸è®¡å…¥å¤±è´¥ï¼‰
                        except Exception as exc:
                            print(f"âš ï¸  ä»»åŠ¡å¼‚å¸¸: {exc}")
                            failed_files_count += 1
                            file_name = os.path.basename(url)
                            failed_files_list.append((file_name, url, str(exc)))
                        
                        # æ£€æŸ¥æ˜¯å¦æ‰€æœ‰ä»»åŠ¡éƒ½å·²å¤„ç†
                        if processed_in_loop >= remaining_tasks:
                            print(f"âœ“ å·²å¤„ç†æ‰€æœ‰ {remaining_tasks} ä¸ªå‰©ä½™ä»»åŠ¡ï¼Œé€€å‡ºå¾ªç¯")
                            break
                    
                    print(f"ğŸ as_completed å¾ªç¯ç»“æŸï¼ˆå¤„ç†äº† {processed_in_loop} ä¸ªä»»åŠ¡ï¼‰")
                
                print(f"âœ“ æ‰€æœ‰ä»»åŠ¡å·²å®Œæˆ: æˆåŠŸ {downloaded_files_count}, å¤±è´¥ {failed_files_count}")
                
                if self.pause_event.is_set():
                    print("â¸ï¸  æ£€æµ‹åˆ°æš‚åœï¼Œå…³é—­æ‰§è¡Œå™¨...")
                    executor.shutdown(wait=False, cancel_futures=True)
                    return
                else:
                    print("ğŸ“Š å‘é€æœ€ç»ˆç»Ÿè®¡...")
                    # ä¸‹è½½å®Œæˆæ—¶å‘é€æœ€ç»ˆçš„UIæ›´æ–°
                    self.stats_update.emit(downloaded_files_count, matched_posts_count)
                    
                    # å‘é€ä¸‹è½½ç»Ÿè®¡æ‘˜è¦
                    summary = {
                        'success': downloaded_files_count,
                        'failed': failed_files_count,
                        'failed_files': failed_files_list[:20]  # æœ€å¤šæ˜¾ç¤º20ä¸ªå¤±è´¥æ–‡ä»¶
                    }
                    self.download_summary.emit(summary)
                    
                    print("ğŸ”’ å…³é—­ä¸‹è½½æ‰§è¡Œå™¨...")
                    
                    executor.shutdown(wait=True)
                    print("âœ… ä¸‹è½½æµç¨‹å®Œæˆï¼")
                    
            except Exception as e:
                # ç­‰å¾…ä¸‹è½½å®Œæˆæ—¶å‘ç”Ÿé”™è¯¯
                executor.shutdown(wait=False, cancel_futures=True)
                raise
                
        except Exception as e:
            self.error.emit(f"æ ‡ç­¾è¿‡æ»¤ä¸‹è½½åè°ƒå™¨å‘ç”Ÿé”™è¯¯: {e}")
        finally:
            self.finished.emit()

